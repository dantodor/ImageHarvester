akka {
  loglevel = "INFO"
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  actor {
    provider = "akka.cluster.ClusterActorRefProvider"
  }

  remote {
    log-remote-lifecycle-events = off
    # Change 127.0.0.1 to your IP
    netty.tcp {
      hostname = "127.0.0.1"
      port = 63905
    }
  }

  cluster {
    roles = [clusterMaster]
    # Change 127.0.0.1 to your IP address
    seed-nodes = ["akka.tcp://ClusterSystem@127.0.0.1:5555"]

    auto-down-unreachable-after = 10s
    unreachable-nodes-reaper-interval = 1s

    failure-detector {
      implementation-class = "akka.remote.PhiAccrualFailureDetector"

      heartbeat-interval = 5s

      threshold = 10.0

      acceptable-heartbeat-pause = 60 s
    }


  }

}


mongo {
  #host = "europeana1.busymachines.com"
  hosts = [
    {
      host = "localhost"
      port = 27017
    }
  ]

  #username = "harvester_europeana"
  #password = "Nhck0zCfcu0M6kK"
  username = ""
  password = ""

  dbName = "newHarvesterBackup"

  jobsPerIP = 500
  maxTasksInMemory = 25000
}

default-limits {
    taskBatchSize = 100

    bandwidthLimitReadInBytesPerSec = 100000000

    minDistanceInMillisBetweenTwoRequest = 1000

    maxConcurrentConnectionsLimit = 2

    connectionTimeoutInMillis = 60000

    maxNrOfRedirects = 10

    responseTimeoutFromSlaveInMillis = 10000

    minTasksPerIPPercentage = 75.0

    receiveTimeoutInterval = 600

    cleanupInterval = 6

    delayForCountingTheStateOfDocuments = 5h

    jobRestarterTimeBetweenRepetitions = 24h
}

ping {
    timePeriod = 86400000

    nrOfPings = 5

    timeoutInterval = 4000
}

eventbus {
    host = "127.0.0.1"

    username = "guest"
    password = "guest"

    incomingQueue = "harvesterIn"

    outgoingQueue = "harvesterOut"
}

IPExceptions {
    maxConcurrentConnectionsLimit = 25

    ips = ["194.199.8.11"]

    ignoredIPs = ["82.102.134.201"]
}

metrics {
  graphiteServer = ""
  masterID = ""
  graphitePort = 8080
}